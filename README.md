# ğŸ™ï¸ React ë§Œë“  Text To Speech ì˜ˆì œ íŒŒì¼ì…ë‹ˆë‹¤.
:octocat: https://light9639.github.io/React-TTS/

![light9639 github io_React-TTS_](https://user-images.githubusercontent.com/95972251/212852447-75ab10d7-7671-415d-8fad-2c04265ebfd5.png)

:sparkles: React ë§Œë“  Text To Speech ì˜ˆì œ íŒŒì¼ì…ë‹ˆë‹¤. :sparkles:
## :tada: React ìƒì„±
- React ìƒì„±
```bash
npm create-react-app my-app
# or
yarn create react-app my-app
```

- viteë¥¼ ì´ìš©í•˜ì—¬ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•˜ë ¤ë©´
```bash
npm create vite@latest
# or
yarn create vite
```
- í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰ í›„ í”„ë¡œì íŠ¸ ì´ë¦„ ë§Œë“  í›„ React ì„ íƒ, Typescirpt ì„ íƒí•˜ë©´ ìƒì„± ì™„ë£Œ.

## âœ’ï¸ App.tsx, getSpeech.ts ìˆ˜ì • ë° ì‘ì„±
### :zap: App.tsx
```js
import { useEffect, useState } from 'react'
import reactLogo from './assets/react.svg'
import './App.css';
import { getSpeech } from "./utils/getSpeech";

function App() {
  const [value, setValue] = useState("ì•ˆë…•í•˜ì„¸ìš”");

  //ìŒì„± ë³€í™˜ ëª©ì†Œë¦¬ preload
  useEffect(() => {
    window.speechSynthesis.getVoices();
  }, []);

  const handleInput = (e: { target: { value: any; }; }) => {
    const { value } = e.target;
    setValue(value);
  };

  const handleButton = () => {
    getSpeech(value);
  };

  return (
    <div className="App">
      <div>
        <a href="https://vitejs.dev" target="_blank">
          <img src="/vite.svg" className="logo" alt="Vite logo" />
        </a>
        <a href="https://reactjs.org" target="_blank">
          <img src={reactLogo} className="logo react" alt="React logo" />
        </a>
      </div>
      <h1>TTS(í•œêµ­ì–´)</h1>
      <p>í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê³  ìŒì„± ë³€í™˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.</p>
      <div className="box">
        <input onChange={handleInput} value={value} />
        <button onClick={handleButton}>ìŒì„± ë³€í™˜</button>
      </div>
    </div>
  )
}

export default App
```

### :zap: getSpeech.ts
```js
export const getSpeech = (text: any) => {
  let voices: any[] = [];

  //ë””ë°”ì´ìŠ¤ì— ë‚´ì¥ëœ voiceë¥¼ ê°€ì ¸ì˜¨ë‹¤.
  const setVoiceList = () => {
    voices = window.speechSynthesis.getVoices();
  };

  setVoiceList();

  if (window.speechSynthesis.onvoiceschanged !== undefined) {
    //voice listì— ë³€ê²½ëì„ë•Œ, voiceë¥¼ ë‹¤ì‹œ ê°€ì ¸ì˜¨ë‹¤.
    window.speechSynthesis.onvoiceschanged = setVoiceList;
  }

  const speech = (txt: string | undefined) => {
    const lang = "ko-KR";
    const utterThis = new SpeechSynthesisUtterance(txt);

    utterThis.lang = lang;

    /* í•œêµ­ì–´ vocie ì°¾ê¸°
      ë””ë°”ì´ìŠ¤ ë³„ë¡œ í•œêµ­ì–´ëŠ” ko-KR ë˜ëŠ” ko_KRë¡œ voiceê°€ ì •ì˜ë˜ì–´ ìˆë‹¤.
    */
    const kor_voice = voices.find(
      (elem) => elem.lang === lang || elem.lang === lang.replace("-", "_")
    );

    //íŒêµ­ì–´ voiceê°€ ìˆë‹¤ë©´ ? utteranceì— ëª©ì†Œë¦¬ë¥¼ ì„¤ì •í•œë‹¤ : ë¦¬í„´í•˜ì—¬ ëª©ì†Œë¦¬ê°€ ë‚˜ì˜¤ì§€ ì•Šë„ë¡ í•œë‹¤.
    if (kor_voice) {
      utterThis.voice = kor_voice;
    } else {
      return;
    }

    //utteranceë¥¼ ì¬ìƒ(speak)í•œë‹¤.
    window.speechSynthesis.speak(utterThis);
  };

  speech(text);
};
```

## :test_tube: ìŒì„±ë³€í™˜ ë²„íŠ¼ í´ë¦­.
- ìŒì„± ë³€í™˜ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ì›¹í˜ì´ì§€ì—ì„œ input ì†ì˜ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì½ì–´ì„œ ìŒì„± ë³€í™˜ì´ ë©ë‹ˆë‹¤.
